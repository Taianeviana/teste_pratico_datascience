{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DESAFIO P&D (Machine Learning) Intelivix\n",
    "\n",
    "### Este desafio consiste em realizar uma análise de sentimentos em  textos opinativos sobre filmes .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\taiane.v.carvalho\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\taiane.v.carvalho\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de dados \n",
    "\n",
    "É feita a leitura dos dados e a exibição das informações que o mesmo possue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./dados/train.tsv', delimiter='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>IdSentenca</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  IdSentenca                                              Texto  \\\n",
       "0   1           1  A series of escapades demonstrating the adage ...   \n",
       "1   2           1  A series of escapades demonstrating the adage ...   \n",
       "2   3           1                                           A series   \n",
       "3   4           1                                                  A   \n",
       "4   5           1                                             series   \n",
       "\n",
       "   Sentimento  \n",
       "0           1  \n",
       "1           2  \n",
       "2           2  \n",
       "3           2  \n",
       "4           2  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A coluna 'Id' tem o mesmo valor do 'Index' do Dataframe, então será removida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train['Id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cada texto possue um 'IdSentenca', a seguir  'IdSentenca' igual a 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IdSentenca</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>3</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>3</td>\n",
       "      <td>Even fans of Ismail Merchant 's work</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>3</td>\n",
       "      <td>Even fans</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>3</td>\n",
       "      <td>Even</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>3</td>\n",
       "      <td>fans</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>3</td>\n",
       "      <td>of Ismail Merchant 's work</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>3</td>\n",
       "      <td>Ismail Merchant 's work</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>3</td>\n",
       "      <td>Ismail Merchant 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>3</td>\n",
       "      <td>Ismail</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>3</td>\n",
       "      <td>Merchant 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>3</td>\n",
       "      <td>Merchant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>3</td>\n",
       "      <td>'s</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>3</td>\n",
       "      <td>work</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3</td>\n",
       "      <td>, I suspect , would have a hard time sitting t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>, I suspect ,</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3</td>\n",
       "      <td>I suspect ,</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3</td>\n",
       "      <td>I suspect</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3</td>\n",
       "      <td>I</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3</td>\n",
       "      <td>suspect</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3</td>\n",
       "      <td>would have a hard time sitting through this one .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>3</td>\n",
       "      <td>would have a hard time sitting through this one</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>3</td>\n",
       "      <td>would</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>3</td>\n",
       "      <td>have a hard time sitting through this one</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>3</td>\n",
       "      <td>a hard time sitting through this one</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3</td>\n",
       "      <td>a hard time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>3</td>\n",
       "      <td>hard time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>3</td>\n",
       "      <td>hard</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>3</td>\n",
       "      <td>time</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>3</td>\n",
       "      <td>sitting through this one</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>3</td>\n",
       "      <td>sitting</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>3</td>\n",
       "      <td>through this one</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>3</td>\n",
       "      <td>through</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>3</td>\n",
       "      <td>this one</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>3</td>\n",
       "      <td>one</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     IdSentenca                                              Texto  Sentimento\n",
       "81            3  Even fans of Ismail Merchant 's work , I suspe...           1\n",
       "82            3               Even fans of Ismail Merchant 's work           2\n",
       "83            3                                          Even fans           2\n",
       "84            3                                               Even           2\n",
       "85            3                                               fans           3\n",
       "86            3                         of Ismail Merchant 's work           2\n",
       "87            3                            Ismail Merchant 's work           2\n",
       "88            3                                 Ismail Merchant 's           2\n",
       "89            3                                             Ismail           2\n",
       "90            3                                        Merchant 's           2\n",
       "91            3                                           Merchant           2\n",
       "92            3                                                 's           2\n",
       "93            3                                               work           2\n",
       "94            3  , I suspect , would have a hard time sitting t...           1\n",
       "95            3                                      , I suspect ,           2\n",
       "96            3                                        I suspect ,           2\n",
       "97            3                                          I suspect           2\n",
       "98            3                                                  I           2\n",
       "99            3                                            suspect           2\n",
       "100           3  would have a hard time sitting through this one .           1\n",
       "101           3    would have a hard time sitting through this one           0\n",
       "102           3                                              would           2\n",
       "103           3          have a hard time sitting through this one           0\n",
       "104           3                                               have           2\n",
       "105           3               a hard time sitting through this one           1\n",
       "106           3                                        a hard time           1\n",
       "107           3                                          hard time           1\n",
       "108           3                                               hard           2\n",
       "109           3                                               time           2\n",
       "110           3                           sitting through this one           1\n",
       "111           3                                            sitting           2\n",
       "112           3                                   through this one           2\n",
       "113           3                                            through           2\n",
       "114           3                                           this one           2\n",
       "115           3                                                one           2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train.IdSentenca == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A função info() mostra algumas informções sobre o conjunt de dados\n",
    "\n",
    "* Total de dados no geral (156.060)\n",
    "* Total de dados não nulos em cada coluna e o tipo do dado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156060 entries, 0 to 156059\n",
      "Data columns (total 3 columns):\n",
      "IdSentenca    156060 non-null int64\n",
      "Texto         156060 non-null object\n",
      "Sentimento    156060 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A base de dados possue 5 classes: Negativo - 0, um pouco negativo - 1, neutro - 2, um pouco positivo - 3 e positivo - 4. \n",
    "* Distribuiçao dos dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    79582\n",
       "3    32927\n",
       "1    27273\n",
       "4     9206\n",
       "0     7072\n",
       "Name: Sentimento, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.Sentimento.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x295cd9afc50>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.Sentimento.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento\n",
    "\n",
    "### A etapa de pré-processamento consistiu  em:\n",
    "\n",
    "* Textos todo em minúsculo utilizando a função lower();\n",
    "* Remoção de StopWords, menos as palavras 'no' e 'not' que podem ser significativas para a classificação da análise de sentimento;\n",
    "* Uso da técnica de Stemming para reduzir as palavras até a sua base (stem). Assim, é possível tratar as palavras originais e suas respectivas derivações de uma mesma maneira;\n",
    "* Remoção de números utilizando a função isdigit(); \n",
    "* Remoção de pontuações utilizando ponctuation da biblioteca string.\n",
    "\n",
    "Para as etapas de remoção de StopWords e Stemming é necessário tokenizar as palavras. Primeiramente, foi realizado um split() nas palavras antes da formatação mas foi observado que no split palavras do tipo \"I'm\" não se separavavam, então o 'split' foi substituido pelo 'word_tokenize'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_remove = ['not', 'no']\n",
    "stopwords_remove = set(stopwords.words('english')).difference(not_remove)\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_text(X):\n",
    "    X = [x.lower() for x in X]\n",
    "    teste = [' '.join(word for word in word_tokenize(review) if word not in stopwords_remove) for review in X]\n",
    "    teste = [' '.join([ps.stem(word) for word in word_tokenize(review)]) for review in teste]\n",
    "    X = [''.join(i for i in s if not i.isdigit()) for s in teste]    \n",
    "    X = [''.join(c for c in s if c not in string.punctuation) for s in teste]\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para realizar a formatação nos textos, eles foram extraídos do dataframe junto com a classificação e o 'Id_sentence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train['Texto'].values.tolist()\n",
    "Y = df_train['Sentimento'].values.tolist()\n",
    "Id = df_train['IdSentenca'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = format_text(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Com os textos formatados foi montado um novo dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = {'IdSentenca': Id, 'Texto': X, 'Sentimento': Y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IdSentenca</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>seri escapad demonstr adag good goos also good...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>seri escapad demonstr adag good goos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>seri</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>seri</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IdSentenca                                              Texto  Sentimento\n",
       "0           1  seri escapad demonstr adag good goos also good...           1\n",
       "1           1               seri escapad demonstr adag good goos           2\n",
       "2           1                                               seri           2\n",
       "3           1                                                              2\n",
       "4           1                                               seri           2"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Após a formatação, alguns dados foram completamente removidos e se torna necessário excluir os espaços nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Texto != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Os espaçamentos antes e depois nos textos também foram removidos, usando a função strip(), para comparações futuras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Texto'] = df['Texto'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IdSentenca</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>seri escapad demonstr adag good goos also good...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>seri escapad demonstr adag good goos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>seri</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>seri</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>escapad demonstr adag good goos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>escapad demonstr adag good goos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>escapad</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>demonstr adag good goos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>demonstr adag</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>adag</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>adag</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>good goos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>good goos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>good goos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>good goos</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>goos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>goos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>goos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>also good gander  occasion amus none amount mu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>also good gander  occasion amus none amount mu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>also</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>also</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>good gander  occasion amus none amount much stori</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>gander  occasion amus none amount much stori</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>gander  occasion amus none amount much stori</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>gander</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>gander</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>gander</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156030</th>\n",
       "      <td>8542</td>\n",
       "      <td>joke unit state</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156031</th>\n",
       "      <td>8543</td>\n",
       "      <td>movi s downfal substitut plot person</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156032</th>\n",
       "      <td>8543</td>\n",
       "      <td>movi s downfal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156033</th>\n",
       "      <td>8543</td>\n",
       "      <td>substitut plot person</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156034</th>\n",
       "      <td>8543</td>\n",
       "      <td>substitut plot person</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156035</th>\n",
       "      <td>8543</td>\n",
       "      <td>substitut plot person</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156036</th>\n",
       "      <td>8543</td>\n",
       "      <td>substitut plot person</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156037</th>\n",
       "      <td>8543</td>\n",
       "      <td>substitut plot</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156038</th>\n",
       "      <td>8543</td>\n",
       "      <td>person</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156039</th>\n",
       "      <td>8544</td>\n",
       "      <td>film darkli atmospher  herrmann quietli sugges...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156040</th>\n",
       "      <td>8544</td>\n",
       "      <td>darkli atmospher  herrmann quietli suggest sad...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156041</th>\n",
       "      <td>8544</td>\n",
       "      <td>darkli atmospher  herrmann quietli suggest sad...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156042</th>\n",
       "      <td>8544</td>\n",
       "      <td>darkli atmospher</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156043</th>\n",
       "      <td>8544</td>\n",
       "      <td>darkli atmospher</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156044</th>\n",
       "      <td>8544</td>\n",
       "      <td>herrmann quietli suggest sad obsess beneath he...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156045</th>\n",
       "      <td>8544</td>\n",
       "      <td>herrmann quietli suggest sad obsess beneath he...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156046</th>\n",
       "      <td>8544</td>\n",
       "      <td>herrmann</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156047</th>\n",
       "      <td>8544</td>\n",
       "      <td>quietli suggest sad obsess beneath hearst s fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156048</th>\n",
       "      <td>8544</td>\n",
       "      <td>suggest sad obsess beneath hearst s forc avunc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156049</th>\n",
       "      <td>8544</td>\n",
       "      <td>suggest sad obsess</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156050</th>\n",
       "      <td>8544</td>\n",
       "      <td>sad obsess</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156051</th>\n",
       "      <td>8544</td>\n",
       "      <td>sad obsess</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156052</th>\n",
       "      <td>8544</td>\n",
       "      <td>sad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156053</th>\n",
       "      <td>8544</td>\n",
       "      <td>beneath hearst s forc avuncular chortl</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156054</th>\n",
       "      <td>8544</td>\n",
       "      <td>hearst s forc avuncular chortl</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>8544</td>\n",
       "      <td>hearst s</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>8544</td>\n",
       "      <td>forc avuncular chortl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortl</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>8544</td>\n",
       "      <td>chortl</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155101 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        IdSentenca                                              Texto  \\\n",
       "0                1  seri escapad demonstr adag good goos also good...   \n",
       "1                1               seri escapad demonstr adag good goos   \n",
       "2                1                                               seri   \n",
       "4                1                                               seri   \n",
       "5                1                    escapad demonstr adag good goos   \n",
       "7                1                    escapad demonstr adag good goos   \n",
       "8                1                                            escapad   \n",
       "9                1                            demonstr adag good goos   \n",
       "10               1                                      demonstr adag   \n",
       "11               1                                           demonstr   \n",
       "12               1                                               adag   \n",
       "14               1                                               adag   \n",
       "15               1                                          good goos   \n",
       "17               1                                          good goos   \n",
       "19               1                                          good goos   \n",
       "21               1                                          good goos   \n",
       "22               1                                               good   \n",
       "23               1                                               goos   \n",
       "25               1                                               goos   \n",
       "26               1                                               goos   \n",
       "27               1  also good gander  occasion amus none amount mu...   \n",
       "28               1  also good gander  occasion amus none amount mu...   \n",
       "29               1                                               also   \n",
       "30               1                                               also   \n",
       "31               1  good gander  occasion amus none amount much stori   \n",
       "32               1       gander  occasion amus none amount much stori   \n",
       "33               1       gander  occasion amus none amount much stori   \n",
       "34               1                                             gander   \n",
       "35               1                                             gander   \n",
       "36               1                                             gander   \n",
       "...            ...                                                ...   \n",
       "156030        8542                                    joke unit state   \n",
       "156031        8543               movi s downfal substitut plot person   \n",
       "156032        8543                                     movi s downfal   \n",
       "156033        8543                              substitut plot person   \n",
       "156034        8543                              substitut plot person   \n",
       "156035        8543                              substitut plot person   \n",
       "156036        8543                              substitut plot person   \n",
       "156037        8543                                     substitut plot   \n",
       "156038        8543                                             person   \n",
       "156039        8544  film darkli atmospher  herrmann quietli sugges...   \n",
       "156040        8544  darkli atmospher  herrmann quietli suggest sad...   \n",
       "156041        8544  darkli atmospher  herrmann quietli suggest sad...   \n",
       "156042        8544                                   darkli atmospher   \n",
       "156043        8544                                   darkli atmospher   \n",
       "156044        8544  herrmann quietli suggest sad obsess beneath he...   \n",
       "156045        8544  herrmann quietli suggest sad obsess beneath he...   \n",
       "156046        8544                                           herrmann   \n",
       "156047        8544  quietli suggest sad obsess beneath hearst s fo...   \n",
       "156048        8544  suggest sad obsess beneath hearst s forc avunc...   \n",
       "156049        8544                                 suggest sad obsess   \n",
       "156050        8544                                         sad obsess   \n",
       "156051        8544                                         sad obsess   \n",
       "156052        8544                                                sad   \n",
       "156053        8544             beneath hearst s forc avuncular chortl   \n",
       "156054        8544                     hearst s forc avuncular chortl   \n",
       "156055        8544                                           hearst s   \n",
       "156056        8544                              forc avuncular chortl   \n",
       "156057        8544                                   avuncular chortl   \n",
       "156058        8544                                          avuncular   \n",
       "156059        8544                                             chortl   \n",
       "\n",
       "        Sentimento  \n",
       "0                1  \n",
       "1                2  \n",
       "2                2  \n",
       "4                2  \n",
       "5                2  \n",
       "7                2  \n",
       "8                2  \n",
       "9                2  \n",
       "10               2  \n",
       "11               2  \n",
       "12               2  \n",
       "14               2  \n",
       "15               2  \n",
       "17               2  \n",
       "19               2  \n",
       "21               3  \n",
       "22               3  \n",
       "23               2  \n",
       "25               2  \n",
       "26               2  \n",
       "27               2  \n",
       "28               2  \n",
       "29               2  \n",
       "30               2  \n",
       "31               2  \n",
       "32               2  \n",
       "33               1  \n",
       "34               2  \n",
       "35               2  \n",
       "36               2  \n",
       "...            ...  \n",
       "156030           2  \n",
       "156031           1  \n",
       "156032           1  \n",
       "156033           1  \n",
       "156034           1  \n",
       "156035           2  \n",
       "156036           1  \n",
       "156037           2  \n",
       "156038           2  \n",
       "156039           2  \n",
       "156040           2  \n",
       "156041           2  \n",
       "156042           2  \n",
       "156043           3  \n",
       "156044           2  \n",
       "156045           2  \n",
       "156046           2  \n",
       "156047           1  \n",
       "156048           2  \n",
       "156049           2  \n",
       "156050           2  \n",
       "156051           1  \n",
       "156052           1  \n",
       "156053           2  \n",
       "156054           2  \n",
       "156055           2  \n",
       "156056           1  \n",
       "156057           3  \n",
       "156058           2  \n",
       "156059           2  \n",
       "\n",
       "[155101 rows x 3 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observando os dados após o pre-processamento é notável que alguns ficaram repetidos. Então foi utilizada a função  'drop_duplicates' para remover os dados repetidos, mantendo a primeira ocorrência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='Texto', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IdSentenca</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>seri escapad demonstr adag good goos also good...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>seri escapad demonstr adag good goos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>seri</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>escapad demonstr adag good goos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>escapad</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IdSentenca                                              Texto  Sentimento\n",
       "0           1  seri escapad demonstr adag good goos also good...           1\n",
       "1           1               seri escapad demonstr adag good goos           2\n",
       "2           1                                               seri           2\n",
       "5           1                    escapad demonstr adag good goos           2\n",
       "8           1                                            escapad           2"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IdSentenca</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>3</td>\n",
       "      <td>even fan ismail merchant s work  suspect  woul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>3</td>\n",
       "      <td>even fan ismail merchant s work</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>3</td>\n",
       "      <td>even fan</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>3</td>\n",
       "      <td>even</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>3</td>\n",
       "      <td>fan</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>3</td>\n",
       "      <td>ismail merchant s work</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>3</td>\n",
       "      <td>ismail merchant s</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>3</td>\n",
       "      <td>ismail</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>3</td>\n",
       "      <td>merchant s</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>3</td>\n",
       "      <td>merchant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>3</td>\n",
       "      <td>s</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>3</td>\n",
       "      <td>work</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3</td>\n",
       "      <td>suspect  would hard time sit one</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>suspect</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3</td>\n",
       "      <td>would hard time sit one</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>3</td>\n",
       "      <td>would</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>3</td>\n",
       "      <td>hard time sit one</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3</td>\n",
       "      <td>hard time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>3</td>\n",
       "      <td>hard</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>3</td>\n",
       "      <td>time</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>3</td>\n",
       "      <td>sit one</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>3</td>\n",
       "      <td>sit</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>3</td>\n",
       "      <td>one</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     IdSentenca                                              Texto  Sentimento\n",
       "81            3  even fan ismail merchant s work  suspect  woul...           1\n",
       "82            3                    even fan ismail merchant s work           2\n",
       "83            3                                           even fan           2\n",
       "84            3                                               even           2\n",
       "85            3                                                fan           3\n",
       "86            3                             ismail merchant s work           2\n",
       "88            3                                  ismail merchant s           2\n",
       "89            3                                             ismail           2\n",
       "90            3                                         merchant s           2\n",
       "91            3                                           merchant           2\n",
       "92            3                                                  s           2\n",
       "93            3                                               work           2\n",
       "94            3                   suspect  would hard time sit one           1\n",
       "95            3                                            suspect           2\n",
       "100           3                            would hard time sit one           1\n",
       "102           3                                              would           2\n",
       "103           3                                  hard time sit one           0\n",
       "106           3                                          hard time           1\n",
       "108           3                                               hard           2\n",
       "109           3                                               time           2\n",
       "110           3                                            sit one           1\n",
       "111           3                                                sit           2\n",
       "112           3                                                one           2"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['IdSentenca'] == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dados com o tamamnho menor que 1 foram removidos da base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Texto'].apply(lambda x: len(x) > 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IdSentenca</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>3</td>\n",
       "      <td>even fan ismail merchant s work  suspect  woul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>3</td>\n",
       "      <td>even fan ismail merchant s work</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>3</td>\n",
       "      <td>even fan</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>3</td>\n",
       "      <td>even</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>3</td>\n",
       "      <td>fan</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>3</td>\n",
       "      <td>ismail merchant s work</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>3</td>\n",
       "      <td>ismail merchant s</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>3</td>\n",
       "      <td>ismail</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>3</td>\n",
       "      <td>merchant s</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>3</td>\n",
       "      <td>merchant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>3</td>\n",
       "      <td>work</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3</td>\n",
       "      <td>suspect  would hard time sit one</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>suspect</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3</td>\n",
       "      <td>would hard time sit one</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>3</td>\n",
       "      <td>would</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>3</td>\n",
       "      <td>hard time sit one</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3</td>\n",
       "      <td>hard time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>3</td>\n",
       "      <td>hard</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>3</td>\n",
       "      <td>time</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>3</td>\n",
       "      <td>sit one</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>3</td>\n",
       "      <td>sit</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>3</td>\n",
       "      <td>one</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     IdSentenca                                              Texto  Sentimento\n",
       "81            3  even fan ismail merchant s work  suspect  woul...           1\n",
       "82            3                    even fan ismail merchant s work           2\n",
       "83            3                                           even fan           2\n",
       "84            3                                               even           2\n",
       "85            3                                                fan           3\n",
       "86            3                             ismail merchant s work           2\n",
       "88            3                                  ismail merchant s           2\n",
       "89            3                                             ismail           2\n",
       "90            3                                         merchant s           2\n",
       "91            3                                           merchant           2\n",
       "93            3                                               work           2\n",
       "94            3                   suspect  would hard time sit one           1\n",
       "95            3                                            suspect           2\n",
       "100           3                            would hard time sit one           1\n",
       "102           3                                              would           2\n",
       "103           3                                  hard time sit one           0\n",
       "106           3                                          hard time           1\n",
       "108           3                                               hard           2\n",
       "109           3                                               time           2\n",
       "110           3                                            sit one           1\n",
       "111           3                                                sit           2\n",
       "112           3                                                one           2"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['IdSentenca'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 82678 entries, 0 to 156059\n",
      "Data columns (total 3 columns):\n",
      "IdSentenca    82678 non-null int64\n",
      "Texto         82678 non-null object\n",
      "Sentimento    82678 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x295d574e208>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.Sentimento.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df['Texto'].values.tolist()\n",
    "Y_train = df['Sentimento'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de Classificação\n",
    "\n",
    "Para essa análise serão utilizados os métodos:\n",
    "\n",
    "* Máquina de Vetor de Suporte (Linear CSV)\n",
    "* Naive Bayes\n",
    "* Regressão Logística\n",
    "\n",
    "Para analisar a solução do melhor modelo foi utilizado o método GridSearchCV que permite avaliar e selecionar sistematicamente os parâmetros de um modelo. Indicando um modelo e os parâmetros a serem testados, é possível avaliar o desempenho do primeiro em função dos segundos por meio de validação cruzada. \n",
    "\n",
    "Na validação cruzada, o conjunto de dados de treinamento é dividido em grupos de tamanho igual. Depois que a partição é feita, o modelo é treinado uma vez para cada um dos grupos. Usando todos os grupos, exceto o da iteração para treinar e esse para validar os resultados. \n",
    "\n",
    "No pipeline além do método de classificação/regressão foi utilizada a técnica 'TfidfVectorizer' do sklearn. \n",
    "\n",
    "O método tf-idf tem o intuito de indicar a importância de uma palavra em relação ao conjunto de dados. O valor tf–idf de uma palavra aumenta proporcionalmente à medida que aumenta o número de ocorrências dela em um exemplo, mas esse valor é equilibrado pela frequência da palavra em todo o conjunto de dados, ou seja, um termo ocorrendo frequentemente em poucos documentos tem um peso alto enquanto um termo que ocorre frequentemente em muitos documentos tem um peso baixo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearCSV com TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "param_grid= {\n",
    "    'tfidf__sublinear_tf':[True, False],\n",
    "    'tfidf__max_df': [0.1, 0.2, 0.3, 0.5, 0.7],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2), (1,3), (1,4)],\n",
    "    'clf__C':[0.1,1.0]   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_word...\n",
       "                                                  max_iter=1000,\n",
       "                                                  multi_class='ovr',\n",
       "                                                  penalty='l2',\n",
       "                                                  random_state=None, tol=0.0001,\n",
       "                                                  verbose=0))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'clf__C': [0.1, 1.0],\n",
       "                         'tfidf__max_df': [0.1, 0.2, 0.3, 0.5, 0.7],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
       "                         'tfidf__sublinear_tf': [True, False]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(pipeline, cv=5, param_grid=param_grid)\n",
    "grid.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56602724, 0.56623286, 0.56228985, 0.56222937, 0.5601853 ,\n",
       "       0.56037882, 0.55925397, 0.5594354 , 0.56602724, 0.56623286,\n",
       "       0.56228985, 0.56222937, 0.5601853 , 0.56037882, 0.55925397,\n",
       "       0.5594354 , 0.56602724, 0.56623286, 0.56228985, 0.56222937,\n",
       "       0.5601853 , 0.56037882, 0.55925397, 0.5594354 , 0.56602724,\n",
       "       0.56622076, 0.56228985, 0.56222937, 0.5601853 , 0.56037882,\n",
       "       0.55925397, 0.5594354 , 0.56602724, 0.56623286, 0.56228985,\n",
       "       0.56222937, 0.5601853 , 0.56037882, 0.55925397, 0.5594354 ,\n",
       "       0.55289194, 0.55278309, 0.54105082, 0.5408694 , 0.54005902,\n",
       "       0.53991388, 0.54003483, 0.54008321, 0.55289194, 0.55277099,\n",
       "       0.54103873, 0.5408694 , 0.54005902, 0.53991388, 0.54003483,\n",
       "       0.54008321, 0.55289194, 0.55277099, 0.54103873, 0.5408694 ,\n",
       "       0.54005902, 0.53991388, 0.54003483, 0.54008321, 0.55289194,\n",
       "       0.55277099, 0.54103873, 0.5408694 , 0.54005902, 0.53991388,\n",
       "       0.54003483, 0.54008321, 0.55289194, 0.55277099, 0.54103873,\n",
       "       0.5408694 , 0.54005902, 0.53991388, 0.54003483, 0.54008321])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means1stem = grid.cv_results_['mean_test_score']\n",
    "means1stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5527310771910303"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means1stem.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 0.1,\n",
       " 'tfidf__max_df': 0.1,\n",
       " 'tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__sublinear_tf': False}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression com TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "param_grid2= {\n",
    "    'tfidf__sublinear_tf':[True, False],\n",
    "    'tfidf__max_df': [0.1, 0.2, 0.3, 0.5, 0.7],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2), (1,3), (1,4)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taiane.v.carvalho\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\taiane.v.carvalho\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_word...\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='warn',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'tfidf__max_df': [0.1, 0.2, 0.3, 0.5, 0.7],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
       "                         'tfidf__sublinear_tf': [True, False]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2 = GridSearchCV(pipeline2, cv=5, param_grid=param_grid2)\n",
    "grid2.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "means2stem = grid2.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5616472943225526"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means2stem.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__max_df': 0.1,\n",
       " 'tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__sublinear_tf': True}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB com TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_word...\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'clf__alpha': [1, 0.1, 0.01, 0.001],\n",
       "                         'tfidf__max_df': [10, 20, 30, 40, 50, 60, 70, 80, 90],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
       "                         'tfidf__sublinear_tf': [True, False]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline3 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "param_grid3 = {\n",
    "    'tfidf__sublinear_tf':[True, False],\n",
    "    'tfidf__max_df': [10, 20, 30, 40 ,50, 60, 70, 80, 90],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2), (1,3), (1,4)],   \n",
    "    'clf__alpha': [1, 0.1, 0.01, 0.001] \n",
    "}\n",
    "\n",
    "grid3 = GridSearchCV(pipeline3, cv=5, param_grid=param_grid3)\n",
    "grid3.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "means3stem = grid3.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49378461987554645"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means3stem.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 1,\n",
       " 'tfidf__max_df': 90,\n",
       " 'tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__sublinear_tf': True}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid3.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foram realizados testes com Lemmatization ao invés do Stemming para comparação dos resultados. \n",
    "\n",
    "A lematização, ao contrário do Stemming, reduz as palavras flexionadas garantindo adequadamente que a palavra raiz pertence à linguagem (continua compreensível). Na lematização, a palavra raiz é chamada de Lemma. Um lemma é a forma canônica, a forma de dicionário ou a forma de citação de um conjunto de palavras. A técniva 'WordNetLemmatizer' foi utilizada para realizar esse processo.\n",
    "\n",
    "O restante do pré-processamento permaneceu igual ao feito anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_text2(X):\n",
    "    X = [x.lower() for x in X]\n",
    "    teste = [' '.join(word for word in word_tokenize(review) if word not in stopwords_remove) for review in X]\n",
    "    teste = [' '.join([lemmatizer.lemmatize(word) for word in word_tokenize(review)]) for review in teste]\n",
    "    X = [''.join(i for i in s if not i.isdigit()) for s in teste]    \n",
    "    X = [''.join(c for c in s if c not in string.punctuation) for s in teste]\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train['Texto'].values.tolist()\n",
    "X = format_text2(X)\n",
    "dados = {'IdSentenca': Id, 'Texto': X, 'Sentimento': Y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dados)\n",
    "df = df[df.Texto != '']\n",
    "df['Texto'] = df['Texto'].str.strip()\n",
    "df = df.drop_duplicates(subset='Texto', keep='first')\n",
    "df = df[df['Texto'].apply(lambda x: len(x) > 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IdSentenca</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>series escapade demonstrating adage good goose...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>series escapade demonstrating adage good goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>escapade demonstrating adage good goose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>escapade</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IdSentenca                                              Texto  Sentimento\n",
       "0           1  series escapade demonstrating adage good goose...           1\n",
       "1           1     series escapade demonstrating adage good goose           2\n",
       "2           1                                             series           2\n",
       "5           1            escapade demonstrating adage good goose           2\n",
       "8           1                                           escapade           2"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df['Texto'].values.tolist()\n",
    "Y_train = df['Sentimento'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Os gridsearchs dos diferentes métodos definidos na etapa anterior foram utilizados para o novo conjunto de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearCSV com TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 0.1,\n",
       " 'tfidf__max_df': 0.1,\n",
       " 'tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__sublinear_tf': False}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,Y_train)\n",
    "means1lemma = grid.cv_results_['mean_test_score']\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5544832623320997"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means1lemma.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression com TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taiane.v.carvalho\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\taiane.v.carvalho\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tfidf__max_df': 0.1,\n",
       " 'tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__sublinear_tf': True}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2.fit(X_train,Y_train)\n",
    "means2lemma = grid2.cv_results_['mean_test_score']\n",
    "grid2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5623676001582979"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means2lemma.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB com TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 1,\n",
       " 'tfidf__max_df': 90,\n",
       " 'tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__sublinear_tf': True}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid3.fit(X_train,Y_train)\n",
    "means3lemma = grid3.cv_results_['mean_test_score']\n",
    "grid3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4805190364783388"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means3lemma.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Final\n",
    "\n",
    "O modelo que apresentou um melhor desempenho foi o LogisticRegression com Lemmatization no pré-processamento e ele será testado com os melhores parâmetros segundo o GridSearch realizado.\n",
    "\n",
    "O método KFold é responsável por dividir o conjunto de dados em n partes e realizar o treinamento e teste com cada um deles. Isso permite que o conjunto de testes escolhido não seja uma amostra  ruim ou muito boa e enviese a análise do resultado da classificação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.06      0.11       603\n",
      "           1       0.47      0.22      0.29      2776\n",
      "           2       0.65      0.90      0.76      9524\n",
      "           3       0.49      0.34      0.40      3414\n",
      "           4       0.57      0.16      0.25       866\n",
      "\n",
      "    accuracy                           0.61     17183\n",
      "   macro avg       0.55      0.34      0.36     17183\n",
      "weighted avg       0.58      0.61      0.56     17183\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.05      0.09       821\n",
      "           1       0.42      0.22      0.29      2942\n",
      "           2       0.60      0.89      0.72      8580\n",
      "           3       0.50      0.35      0.41      3799\n",
      "           4       0.54      0.13      0.21      1041\n",
      "\n",
      "    accuracy                           0.57     17183\n",
      "   macro avg       0.50      0.33      0.34     17183\n",
      "weighted avg       0.54      0.57      0.52     17183\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.05      0.09       799\n",
      "           1       0.45      0.21      0.29      3118\n",
      "           2       0.60      0.89      0.72      8478\n",
      "           3       0.49      0.37      0.42      3710\n",
      "           4       0.56      0.12      0.19      1078\n",
      "\n",
      "    accuracy                           0.57     17183\n",
      "   macro avg       0.51      0.33      0.34     17183\n",
      "weighted avg       0.54      0.57      0.51     17183\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.09      0.15       888\n",
      "           1       0.46      0.23      0.31      3162\n",
      "           2       0.60      0.88      0.71      8474\n",
      "           3       0.47      0.35      0.40      3642\n",
      "           4       0.50      0.13      0.21      1017\n",
      "\n",
      "    accuracy                           0.56     17183\n",
      "   macro avg       0.52      0.34      0.36     17183\n",
      "weighted avg       0.54      0.56      0.51     17183\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.06      0.11       835\n",
      "           1       0.47      0.24      0.32      3394\n",
      "           2       0.58      0.88      0.70      8240\n",
      "           3       0.51      0.36      0.42      3622\n",
      "           4       0.54      0.15      0.23      1091\n",
      "\n",
      "    accuracy                           0.56     17182\n",
      "   macro avg       0.50      0.34      0.36     17182\n",
      "weighted avg       0.53      0.56      0.51     17182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "accuracy = []\n",
    "for train_index, test_index in kf.split(X_train):    \n",
    "    \n",
    "    X_train_, X_test_ = [X_train[index] for index in train_index], [X_train[index] for index in test_index]\n",
    "    y_train_, y_test_ = [Y_train[index] for index in train_index], [Y_train[index] for index in test_index]\n",
    "    \n",
    "    \n",
    "    vectorizer = TfidfVectorizer(sublinear_tf= True, max_df=0.1, ngram_range=(1,1))\n",
    "    X_train_transformed = vectorizer.fit_transform(X_train_)\n",
    "   \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train_transformed, y_train_)\n",
    "    \n",
    "    X_teste_transformed = vectorizer.transform(X_test_)\n",
    "    predict = clf.predict(X_teste_transformed)\n",
    "    \n",
    "    accuracy.append(accuracy_score(y_test_,predict))\n",
    "    print(classification_report(y_test_,predict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O valor médio de acurácia para o modelo é de:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5740622553226544"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerações finais\n",
    "\n",
    "Os dados de sentimento não estavam balanceados, como pode ser visto nos gráficos mostrados no início. Observando o resultado, é possível notar que quanto mais dados a classe possui, melhor o resultado do treinamento.  Um balanceamento dos dados poderia apresentar uma possível melhora nos resultados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
